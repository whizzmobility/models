# Use your own cityscapes preprocessed dataset. 79% meanIoU.
runtime:
  distribution_strategy: 'mirrored'
  mixed_precision_dtype: 'float32'
  num_gpus: 0
task:
  model:
    num_classes: 19
    input_size: [null, null, 3]
    backbone:
      type: 'dilated_resnet'
      dilated_resnet:
        model_id: 101
        output_stride: 16
        stem_type: 'v1'
        se_ratio: 0.25
        stochastic_depth_drop_rate: 0.2
        multigrid: [1, 2, 4]
        last_stage_repeats: 1
    decoder:
      aspp:
        level: 4
        dilation_rates: [6, 12, 18]
        pool_kernel_size: [512, 1024]
    head:
      feature_fusion: 'deeplabv3plus'
      level: 4
      num_convs: 2
      low_level: 2
      low_level_num_filters: 48
    norm_activation:
      activation: 'swish'
      norm_epsilon: 0.001
      norm_momentum: 0.99
      use_sync_bn: true
  losses:
    l2_weight_decay: 0.0001
    top_k_percent_pixels: 1.0  # only backpropagate loss for the topk 100% pixels.
  train_data:
    output_size: [512, 1024]
    train_on_crops: true
    input_path: ''
    tfds_data_dir: 'D:/data'
    tfds_name: 'cityscapes/semantic_segmentation'
    tfds_split: 'train'
    tfds_download: True
    is_training: true
    global_batch_size: 4 #16
    dtype: 'float32'
    aug_rand_hflip: true
    aug_scale_max: 2.0
    aug_scale_min: 0.5
  validation_data:
    output_size: [1024, 2048]
    input_path: ''
    tfds_data_dir: 'D:/data'
    tfds_name: 'cityscapes/semantic_segmentation'
    tfds_split: 'validation'
    tfds_download: True
    is_training: false
    global_batch_size: 1 #16
    dtype: 'float32'
    drop_remainder: false
    resize_eval_groundtruth: true
trainer:
  optimizer_config:
    learning_rate:
      polynomial:
        decay_steps: 360000 #90000
        initial_learning_rate: 0.01
        power: 0.9
      type: polynomial
    optimizer:
      sgd:
        momentum: 0.9
      type: sgd
    warmup:
      linear:
        name: linear
        warmup_learning_rate: 0
        warmup_steps: 3700 #925
      type: linear
  steps_per_loop: 740 #185
  summary_interval: 740 #185
  train_steps: 360000 #90000
  validation_interval: 740 #185
  validation_steps: 496 #31
  checkpoint_interval: 740 #185
